{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyOwKr0eHVE2p4Y9YPmOzFG3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Hz49y27ddDlu"},"outputs":[],"source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col,concat,lit,floor,rand\n","spark = SparkSession.builder.appName(\"ETLPractice\").getOrCreate()\n","source_path = \"orders.csv\"\n","target_path = \"order_result.csv\"\n","load_data = spark.read.csv(\"orders.csv\",header = True, inferSchema = True)"]},{"cell_type":"code","source":["load_data.columns\n","load_data.show(5)"],"metadata":{"id":"Lhs9FqWNedIt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" #Transformation 1: Concatenate First and Last Names\n","load_data = load_data.withColumn('full_name', concat(col('cust_fname'), lit(' '), col('cust_lname')))\n","load_data.show(10)"],"metadata":{"id":"gt_3cMR6ejTa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Transformation 2: Calculate Net Salary (subtract 10% as taxes)\n","load_data = load_data.withColumn('net_salary', floor(lit(10000) + rand() * lit(50)))\n","load_data.show(10)"],"metadata":{"id":"mD90uuOvlGIt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# addingÂ age column\n","load_data = load_data.withColumn('age', floor(lit(20) + rand() * lit(31)))\n","load_data.show(10)"],"metadata":{"id":"-jOsAhsFlP0w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Filter by Age (age >= 30)\n","load_data = load_data.filter(col('age')>= 30)\n","load_data.show()"],"metadata":{"id":"FFQDT3y-lXzb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Group by Age and Calculate Average Salary\n","avg_salary_by_age = load_data.groupBy('age').agg({'net_salary' :'avg'}).withColumnRenamed('avg(salary)', 'avg_salary')\n","avg_salary_by_age.show()"],"metadata":{"id":"c5ViEdvomCeS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["load_data = load_data.orderBy(\"age\")\n","load_data.show()"],"metadata":{"id":"-UKpDZ9WpLmy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the transformed data to an external CSV file\n","load_data.write.csv(target_path, mode='overwrite', header=True)"],"metadata":{"id":"8Mo4S1Y2pYGa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# File location and type\n","file_location = \"/content/orders.csv\"\n","file_type = \"csv\"\n","\n","# CSV options\n","infer_schema = \"false\"\n","first_row_is_header = \"false\"\n","delimiter = \",\"\n","\n","# The applied options are for CSV files. For other file types, these will be ignored.\n","df = spark.read.format(file_type) \\\n","  .option(\"inferSchema\", infer_schema) \\\n","  .option(\"header\", first_row_is_header) \\\n","  .option(\"sep\", delimiter) \\\n","  .load(file_location)\n","\n","display(df)\n","df.createOrReplaceTempView(\"tempdata\")"],"metadata":{"id":"_PP2MeW__hne"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spark.sql(\"select * from tempdata\").show()\n","df.select(\"_c0\",\"_c1\").show(5)"],"metadata":{"id":"804wj2fYEXdd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spark.sql(\"\"\"SELECT * From tempdata WHERE _c4='inactive'\"\"\").show()"],"metadata":{"id":"miOmJjzNEgdp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# File location and type\n","file_location = \"/content/Simple_zip.csv\"\n","file_type = \"csv\"\n","\n","# CSV options\n","infer_schema = \"false\"\n","first_row_is_header = \"false\"\n","delimiter = \",\"\n","\n","# The applied options are for CSV files. For other file types, these will be ignored.\n","df = spark.read.format(file_type) \\\n","  .option(\"inferSchema\", infer_schema) \\\n","  .option(\"header\", first_row_is_header) \\\n","  .option(\"sep\", delimiter) \\\n","  .load(file_location)\n","\n","display(df)\n","df.createOrReplaceTempView(\"tempdata\")"],"metadata":{"id":"3uUYldlsIrIA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spark.sql(\"select * from tempdata\").show()\n","df.select(\"_c0\",\"_c1\").show(5)"],"metadata":{"id":"9hy90p0SI4Yu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spark.sql(\"\"\"SELECT * From tempdata WHERE _c4='AL'\"\"\").show(5)"],"metadata":{"id":"Zo64ZGphJjd_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# File location and type\n","file_location = \"/content/Simple_zip.csv\"\n","file_type = \"csv\"\n","\n","# CSV options\n","infer_schema = \"false\"\n","first_row_is_header = \"true\"\n","delimiter = \",\"\n","\n","# The applied options are for CSV files. For other file types, these will be ignored.\n","df = spark.read.format(file_type) \\\n","  .option(\"inferSchema\", infer_schema) \\\n","  .option(\"header\", first_row_is_header) \\\n","  .option(\"sep\", delimiter) \\\n","  .load(file_location)\n","\n","display(df)\n","df.createOrReplaceTempView(\"customer\")"],"metadata":{"id":"Azuhc_6KJtFL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spark.sql(\"select * from customer\").show()\n","df.select(\"RecordNumber\",\"Country\").show(5)"],"metadata":{"id":"_XFxIDoPJ2Xs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spark.sql(\"\"\"SELECT * From customer WHERE state='PR'\"\"\").show(5)"],"metadata":{"id":"CpM_LpT9J73B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spark.sql(\"\"\"select * FROM customer WHERE state in ('PR','AL','FL')order by state \"\"\").show(10)"],"metadata":{"id":"QeX9FSr7KAdE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spark.sql(\"\"\"SELECT state,count(*) as count FROM customer GROUP BY state\"\"\").show()"],"metadata":{"id":"KWyCk-APKNPL"},"execution_count":null,"outputs":[]}]}